{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4b30e01",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import random\n",
    "from datasets import Dataset\n",
    "\n",
    "data_folder    = ''\n",
    "train_folder   = f'{data_folder}/train'\n",
    "test_folder    = f'{data_folder}/test'\n",
    "\n",
    "sorted_dict_path = ''\n",
    "\n",
    "# PAFT orders for datasets\n",
    "with open(sorted_dict_path, 'r') as f:\n",
    "    sorted_order_dict = eval(f.read())\n",
    "\n",
    "# Info about datasets\n",
    "data_info_path = ''\n",
    "data_info = pd.read_csv(data_info_path, index_col='df_name').sort_values('row_number')\n",
    "\n",
    "data_info"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99a8c13c",
   "metadata": {},
   "source": [
    "# Datasets for standard training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15a2cdb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "PAFT_ORDER = True\n",
    "\n",
    "output_folder = f\"./data/datasets_for_standard_FT/{'PAFT' if PAFT_ORDER else 'GREAT'}\"\n",
    "\n",
    "for df_name in data_info.index:\n",
    "    df_train = pd.read_csv(f'{train_folder}/{df_name}.csv')\n",
    "    \n",
    "    if PAFT_ORDER:\n",
    "        order = sorted_order_dict[df_name]\n",
    "\n",
    "        if order == '':\n",
    "            # No df in calculated func dependencies\n",
    "            order = df_train.columns.tolist() # a fixed random order for all samples\n",
    "            # random order\n",
    "            random.shuffle(order)\n",
    "            order = ','.join(order)\n",
    "\n",
    "    else:\n",
    "        order = df_train.columns.tolist()\n",
    "        order = ','.join(order)\n",
    "\n",
    "    df_train = df_train[order.split(',')] * 1\n",
    "\n",
    "    df_text = []\n",
    "    for i in range(len(df_train)):\n",
    "        row = df_train.loc[i]\n",
    "        cols, vals = row.index, row.values\n",
    "\n",
    "        text = ', '.join([f'{col} is {int(val) if val.is_integer() else round(val, 3)}' for col, val in zip(cols, vals)])\n",
    "        df_text.append(text)\n",
    "\n",
    "\n",
    "    df_for_tuning_pandas = pd.DataFrame({'output' : df_text})\n",
    "    df_for_tuning_pandas['instruction'] = 'Generate a synthetic sample giving an order of the columns. There must be no columns that were not provided in order!'\n",
    "    df_for_tuning_pandas['input'] = order\n",
    "\n",
    "    dataset_DS = Dataset.from_pandas(df_for_tuning_pandas)\n",
    "\n",
    "    dataset_DS.save_to_disk(f'{output_folder}/{df_name}_prompts_train')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3d7fbe1",
   "metadata": {},
   "source": [
    "# Datasets for batch training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f9ae0ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "PAFT_ORDER = True\n",
    "output_folder = f\"./data/datasets_for_batch_FT/{'PAFT' if PAFT_ORDER else 'GREAT'}\"\n",
    "    \n",
    "N_batch = 10\n",
    "\n",
    "for df_name in data_info.index:\n",
    "    df_train = pd.read_csv(f'{train_folder}/{df_name}.csv')\n",
    "    old_shape = df_train.shape\n",
    "\n",
    "    df_train = df_train.head(len(df_train) - len(df_train) % N_batch)\n",
    "\n",
    "    if PAFT_ORDER:\n",
    "        order = sorted_order_dict[df_name]\n",
    "\n",
    "        if order == '':\n",
    "            # No df in calculated func dependencies\n",
    "            order = df_train.columns.tolist() # a fixed random order for all samples\n",
    "            # random order\n",
    "            random.shuffle(order)\n",
    "            order = ','.join(order)\n",
    "\n",
    "    else:\n",
    "        order = df_train.columns.tolist()\n",
    "        order = ','.join(order)\n",
    "\n",
    "    df_train = df_train[order.split(',')] * 1\n",
    "\n",
    "    df_text = []\n",
    "    for i in range(len(df_train)):\n",
    "        row = df_train.loc[i]\n",
    "        cols, vals = row.index, row.values\n",
    "\n",
    "        text = ', '.join([f'{col} is {int(val) if val.is_integer() else round(val, 3)}' for col, val in zip(cols, vals)])\n",
    "        df_text.append(text)\n",
    "\n",
    "    df_text_Nbatch = []\n",
    "    number_of_iters = len(df_text) // N_batch\n",
    "\n",
    "    for i in range(number_of_iters):\n",
    "        df_text_slice = df_text[i*N_batch:(i+1)*N_batch]\n",
    "        N_samples_line = ''\n",
    "        for sample_idx, sample in enumerate(df_text_slice):\n",
    "            N_samples_line += f'Sample {sample_idx}: {sample}\\n'\n",
    "        \n",
    "        df_text_Nbatch.append(N_samples_line)\n",
    "        \n",
    "    df_for_tuning_pandas = pd.DataFrame({'output' : df_text_Nbatch})\n",
    "    df_for_tuning_pandas['instruction'] = f'Generate {N_batch} synthetic samples giving an order of the columns. There must be no columns that were not provided in order!'\n",
    "    df_for_tuning_pandas['input'] = order\n",
    "\n",
    "    dataset_DS = Dataset.from_pandas(df_for_tuning_pandas)\n",
    "\n",
    "    dataset_DS.save_to_disk(f'{output_folder}/{df_name}_prompts_train')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bacda8d",
   "metadata": {},
   "source": [
    "# Datasets for batch anon training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4376160c",
   "metadata": {},
   "outputs": [],
   "source": [
    "PAFT_ORDER = True\n",
    "\n",
    "N_batch = 10\n",
    "\n",
    "output_folder = f\"./data/datasets_for_batch_anon_FT/{'PAFT' if PAFT_ORDER else 'GREAT'}\"\n",
    "\n",
    "for df_name in data_info.index:\n",
    "    df_train = pd.read_csv(f'{train_folder}/{df_name}.csv')\n",
    "    old_shape = df_train.shape\n",
    "\n",
    "    df_train = df_train.head(len(df_train) - len(df_train) % N_batch)\n",
    "    print(df_name, \", old shape:\", old_shape, 'new shape:', df_train.shape)\n",
    "\n",
    "    if PAFT_ORDER:\n",
    "        order = sorted_order_dict[df_name]\n",
    "\n",
    "        if order == '':\n",
    "            # No df in calculated func dependencies\n",
    "            order = df_train.columns.tolist() # a fixed random order for all samples\n",
    "            # random order\n",
    "            random.shuffle(order)\n",
    "            order = ','.join(order)\n",
    "\n",
    "    else:\n",
    "        order = df_train.columns.tolist()\n",
    "        order = ','.join(order)\n",
    "\n",
    "    df_train = df_train[order.split(',')] * 1\n",
    "\n",
    "    print(df_name, \":\", order)\n",
    "\n",
    "    df_text = []\n",
    "    cols = [f'col{i}' for i in range(1, len(df_train.columns) + 1)]\n",
    "\n",
    "    for i in range(len(df_train)):\n",
    "        row = df_train.loc[i]\n",
    "        vals = row.values\n",
    "\n",
    "        text = ', '.join([f'{col} is {int(val) if val.is_integer() else round(val, 3)}' for col, val in zip(cols, vals)])\n",
    "        df_text.append(text)\n",
    "\n",
    "    df_text_Nbatch = []\n",
    "    number_of_iters = len(df_text) // N_batch\n",
    "\n",
    "    for i in range(number_of_iters):\n",
    "        df_text_slice = df_text[i*N_batch:(i+1)*N_batch]\n",
    "        N_samples_line = ''\n",
    "        for sample_idx, sample in enumerate(df_text_slice):\n",
    "            N_samples_line += f'Sample {sample_idx}: {sample}\\n'\n",
    "        \n",
    "        df_text_Nbatch.append(N_samples_line)\n",
    "        \n",
    "    df_for_tuning_pandas = pd.DataFrame({'output' : df_text_Nbatch})\n",
    "    df_for_tuning_pandas['instruction'] = f'Generate {N_batch} synthetic samples giving an order of the columns. There must be no columns that were not provided in order!'\n",
    "    df_for_tuning_pandas['input'] = ','.join(cols)\n",
    "\n",
    "    dataset_DS = Dataset.from_pandas(df_for_tuning_pandas)\n",
    "\n",
    "    dataset_DS.save_to_disk(f'{output_folder}/{df_name}_prompts_train')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
